{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/petrojm/miniconda3/envs/complex_rag/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import pickle # remove\n",
    "import shutil\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "kit_dir = os.path.abspath(os.path.join(current_dir, \"..\")) # absolute path for ekr directory\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, \"..\")) # absolute path for starter-kit directory\n",
    "\n",
    "sys.path.append(kit_dir)\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "from enterprise_knowledge_retriever.src.document_retrieval import DocumentRetrieval\n",
    "\n",
    "CONFIG_PATH = os.path.join(kit_dir,'config.yaml')\n",
    "PERSIST_DIRECTORY = os.path.join(kit_dir,f\"data/my-vector-db\")\n",
    "#save_location = kit_dir + \"/data/my-vector-db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/petrojm/miniconda3/envs/complex_rag/lib/python3.11/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "2024-06-13 23:17:41,116 [ERROR] - Following dependencies are missing: pikepdf. Please install them using `pip install pikepdf`.\n",
      "2024-06-13 23:17:41,119 [WARNING] - PDF text extraction failed, skip text extraction...\n",
      "2024-06-13 23:17:44,050 [INFO] - Processing entire page OCR with tesseract...\n",
      "2024-06-13 23:17:50,419 [INFO] - Processing entire page OCR with tesseract...\n",
      "2024-06-13 23:17:58,305 [INFO] - Processing entire page OCR with tesseract...\n",
      "2024-06-13 23:18:04,355 [INFO] - Processing entire page OCR with tesseract...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "# Specify PDF file\n",
    "pdf_file = kit_dir + '/data/tmp/milan_paper.pdf'\n",
    "\n",
    "# Initialize DocumentRetrieval class\n",
    "documentRetrieval =  DocumentRetrieval()\n",
    "#print(documentRetrieval.loaders)\n",
    "\n",
    "# Get pdf text\n",
    "raw_text = []\n",
    "meta_data = []\n",
    "loader = UnstructuredPDFLoader(pdf_file)\n",
    "docs_unstructured = loader.load()\n",
    "for doc in docs_unstructured:\n",
    "    raw_text.append(doc.page_content)\n",
    "    meta_data.append({\"filename\": pdf_file})\n",
    "\n",
    "#raw_text, meta_data = documentRetrieval.get_data_for_splitting(docs)\n",
    "#with open(kit_dir+'/streamlit/'+'raw_text.pkl', 'rb') as file:\n",
    "#    raw_text = pickle.load(file)\n",
    "#with open(kit_dir+'/streamlit/'+'meta_data.pkl', 'rb') as file:\n",
    "#    meta_data = pickle.load(file)\n",
    "\n",
    "# Get the text chunks\n",
    "text_chunks = documentRetrieval.get_text_chunks_with_metadata(docs=raw_text, meta_data=meta_data)\n",
    "print(len(text_chunks))\n",
    "#print(type(text_chunks[0])) # list of langchain_core.documents.base.Document\n",
    "#print(text_chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 23:18:13,804 [INFO] - Load pretrained SentenceTransformer: intfloat/e5-large-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 23:18:21,892 [INFO] - Use pytorch device: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n",
      "The directory Chroma has been deleted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 23:18:22,682 [INFO] - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2024-06-13 23:18:41,436 [INFO] - Vector store saved to /Users/petrojm/Documents/projects/workshops/new/ai-starter-kit/enterprise_knowledge_retriever/data/my-vector-db\n"
     ]
    }
   ],
   "source": [
    "# Create vector store\n",
    "embeddings = documentRetrieval.load_embedding_model()\n",
    "if os.path.exists(PERSIST_DIRECTORY):\n",
    "    shutil.rmtree(PERSIST_DIRECTORY)\n",
    "    print(f\"The directory Chroma has been deleted.\")\n",
    "#vectorstore = documentRetrieval.create_vector_store(text_chunks, embeddings, output_db=None)\n",
    "vectorstore = documentRetrieval.create_vector_store(text_chunks, embeddings, output_db=PERSIST_DIRECTORY)\n",
    "\n",
    "# Create conversation chain\n",
    "documentRetrieval.init_retriever(vectorstore)\n",
    "conversation = documentRetrieval.get_qa_retrieval_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is DFNN-BC?\n",
      " DFNN-BC stands for Deep Feedforward Neural Network with Boundary Conditions. It is a neural network model developed for efficient evaluation of thermophysical properties in numerical simulations of complex real-fluid flows. The model incorporates boundary information and can be coupled to a flow solver in a robust manner. It is able to accelerate the evaluation of real-fluid properties and overall flowfield simulation significantly, while also reducing memory usage.\n",
      "3\n",
      "\n",
      "Source #1:\n",
      "Source: /Users/petrojm/Documents/projects/workshops/new/ai-starter-kit/enterprise_knowledge_retriever/data/tmp/milan_paper, Text: \n",
      "A neural network model, referred to as DFNN-BC, is developed to achieve the desired accuracy when incorporating boundary information (i.e., the flow behavior along the bound- aries of the domain). The model can be coupled to a flow solver in a robust manner. The proposed methodology is implemented and tested in two model problems with differ- ent numerical formulations: (1) two-dimensional turbulent mixing of gaseous oxygen and liquid kerosene in a rocket injector using a primitive-variable based formulation, and (2) a quasi-one-dimensional counterflow diffusion flame for cryogenic hydrogen combustion using a conservative-variable based formulation. We thus cover two widely-used methods for the simulation of fluid flows at supercritical conditions.\n",
      "\n",
      "{'filename': '/Users/petrojm/Documents/projects/workshops/new/ai-starter-kit/enterprise_knowledge_retriever/data/tmp/milan_paper.pdf'}\n",
      "\n",
      "Source #2:\n",
      "Source: /Users/petrojm/Documents/projects/workshops/new/ai-starter-kit/enterprise_knowledge_retriever/data/tmp/milan_paper, Text: \n",
      "A deep-learning based approach is developed for efficient evaluation of thermophysical properties in numerical simulations of complex real-fluid flows. The work enables a signifi- cant improvement of computational efficiency by replacing direct calculation of the equation of state with a deep feedforward neural network with appropriate boundary information (DFNN-BC). The proposed method can be coupled to a flow solver in a robust manner. Depending on the numerical formulation of the flow solver, the neural network takes in either the primitive or conservative variables, including the chemical composition of the sys- tem, and calculates all relevant fluid properties for the subsequent routines in the solver. Two test problems are employed to validate the proposed methodology. The first uses a preconditioning scheme with dual-time integration for the simulation of swirl injector flow dynamics under supercritical conditions. The second uses a conservative-variable based for- mulation for the simulation of laminar counterflow diffusion flames for cryogenic combustion. A parametric analysis is performed to optimize the numbers of hidden layers and neurons per hidden layer. The\n",
      "\n",
      "{'filename': '/Users/petrojm/Documents/projects/workshops/new/ai-starter-kit/enterprise_knowledge_retriever/data/tmp/milan_paper.pdf'}\n",
      "\n",
      "Source #3:\n",
      "Source: /Users/petrojm/Documents/projects/workshops/new/ai-starter-kit/enterprise_knowledge_retriever/data/tmp/milan_paper, Text: \n",
      "a conservative-variable based for- mulation for the simulation of laminar counterflow diffusion flames for cryogenic combustion. A parametric analysis is performed to optimize the numbers of hidden layers and neurons per hidden layer. The computational accuracy, efficiency, and memory requirements of the neural network are examined. The DFNN-BC model accelerates the evaluation of real-fluid properties by a factor of 2.43 and 3.7 for the two test problems, respectively, and the overall flowfield simulation by 1.5 and 2.3, respectively. In addition, the memory usage is reduced by up to five orders of magnitude in comparison with the table look-up method.\n",
      "\n",
      "{'filename': '/Users/petrojm/Documents/projects/workshops/new/ai-starter-kit/enterprise_knowledge_retriever/data/tmp/milan_paper.pdf'}\n"
     ]
    }
   ],
   "source": [
    "# Ask questions about your data\n",
    "user_question = \"What is DFNN-BC?\"\n",
    "#user_question = \"What is monolithic LLMs?\"\n",
    "\n",
    "response = conversation.invoke({\"question\":user_question})\n",
    "#print(response)\n",
    "print(response['question'])\n",
    "print(response['answer'])\n",
    "print(len(response['source_documents']))\n",
    "print('\\nSource #1:')\n",
    "print(response['source_documents'][0].page_content)\n",
    "print(response['source_documents'][0].metadata)\n",
    "\n",
    "print('\\nSource #2:')\n",
    "print(response['source_documents'][1].page_content)\n",
    "print(response['source_documents'][1].metadata)\n",
    "\n",
    "print('\\nSource #3:')\n",
    "print(response['source_documents'][2].page_content)\n",
    "print(response['source_documents'][2].metadata)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "complex_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
